{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6898670,"sourceType":"datasetVersion","datasetId":3954404},{"sourceId":6925544,"sourceType":"datasetVersion","datasetId":3953428}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Colab for roop-unleashed - Gradio version\nhttps://github.com/C0untFloyd/roop-unleashed\n","metadata":{"id":"G9BdiCppV6AS"}},{"cell_type":"markdown","source":"Installing & preparing requirements","metadata":{"id":"0ZYRNb0AWLLW"}},{"cell_type":"code","source":"!git lfs install\n!git clone https://huggingface.co/spaces/victorisgeek/DeepfakeFaceswap\n%cd DeepfakeFaceswap\n!mv /kaggle/input/config/config_colab.yaml config.yaml\n!pip install pip install -r requirements.txt","metadata":{"id":"t1yPuhdySqCq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# - Option 2: Running with Ngrok - #\n\nNgrok_token = \"2gS3eRkkxfYovOWlktehR9RQ00T_7cznE4Jvh39n9LNr84wNM\" #@param {type:\"string\"}\n# Put your ngrok token here (obtainable from https://ngrok.com)\n\nNgrok_domain = \"\" # optional, leave empty if you don't have a domain\n\n# -------------------------------- #\n\n!pip install pyngrok\n\nfrom pyngrok import ngrok, conf\nimport fileinput\nimport sys\n\nif Ngrok_token!=\"\":\n  ngrok.kill()\n  srv=ngrok.connect(7860 , pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token),\n                    bind_tls=True, domain=Ngrok_domain).public_url\n  print(srv)\n  get_ipython().system(\"python app.py\")\nelse:\n  print('An ngrok token is required. You can get one on https://ngrok.com and paste it into the ngrok_token field.')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:48:53.517802Z","iopub.execute_input":"2024-05-14T10:48:53.518741Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyngrok in /opt/conda/lib/python3.10/site-packages (7.1.6)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.1)\nhttps://e50a-35-223-101-155.ngrok-free.app\n/opt/conda/lib/python3.10/site-packages/gradio_client/documentation.py:103: UserWarning: Could not get documentation group for <class 'gradio.mix.Parallel'>: No known documentation group for module 'gradio.mix'\n  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n/opt/conda/lib/python3.10/site-packages/gradio_client/documentation.py:103: UserWarning: Could not get documentation group for <class 'gradio.mix.Series'>: No known documentation group for module 'gradio.mix'\n  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n\n********** Running on CPU **********\n\ndownload_path: /root/.insightface/models/buffalo_l\nDownloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n100%|████████████████████████████████| 281857/281857 [00:04<00:00, 57659.30KB/s]\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\nset det-size: (640, 640)\nRunning on local URL:  http://127.0.0.1:7860\nIMPORTANT: You are using gradio version 3.40.1, however version 4.29.0 is available, please upgrade.\n--------\n\nTo create a public link, set `share=True` in `launch()`.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Running roop-unleashed with default config","metadata":{"id":"u_4JQiSlV9Fi"}},{"cell_type":"code","source":"!apt-get update && apt-get install ffmpeg libsm6 libxext6  -y\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download generated images folder\n(only needed if you want to zip the generated output)","metadata":{"id":"UdQ1VHdI8lCf"}},{"cell_type":"code","source":"import shutil\nimport os\nfrom google.colab import files\n\ndef zip_directory(directory_path, zip_path):\n    shutil.make_archive(zip_path, 'zip', directory_path)\n\n# Set the directory path you want to download\ndirectory_path = '/content/roop-unleashed/output'\n\n# Set the zip file name\nzip_filename = 'fake_output.zip'\n\n# Zip the directory\nzip_directory(directory_path, zip_filename)\n\n# Download the zip file\nfiles.download(zip_filename+'.zip')\n","metadata":{"id":"oYjWveAmw10X","outputId":"5b4c3650-f951-434a-c650-5525a8a70c1e","trusted":true},"execution_count":null,"outputs":[]}]}